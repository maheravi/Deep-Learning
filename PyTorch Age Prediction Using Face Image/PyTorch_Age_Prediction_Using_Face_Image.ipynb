{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheravi/Deep-Learning/blob/main/PyTorch%20Age%20Prediction%20Using%20Face%20Image/PyTorch_Age_Prediction_Using_Face_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpXvrCR8v3R9",
        "outputId": "af70cdce-045d-4dc5-b9df-39d32fc6ff15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NoBJZjNw2FG",
        "outputId": "0a83199a-907b-4af5-d7e8-fbafa7ab0dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "utkface-new.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d jangedoo/utkface-new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMpnvQDSw9F9",
        "outputId": "3e8a8c0d-f047-48ea-c7b6-f84bf58702f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace UTKFace/100_0_0_20170112213500903.jpg.chip.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: NA\n"
          ]
        }
      ],
      "source": [
        "!unzip -qq utkface-new.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb"
      ],
      "metadata": {
        "id": "pj2TSxeRb4um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "o5Cv_mGAxETF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"AgePrediction\", entity=\"ma_heravi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "fkDVGPgjcTrc",
        "outputId": "0d37fba1-665c-43d9-8dfc-2e1b5de846de"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/ma_heravi/AgePrediction/runs/159qfjuo\" target=\"_blank\">rural-resonance-1</a></strong> to <a href=\"https://wandb.ai/ma_heravi/AgePrediction\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f6c03773a50>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ma_heravi/AgePrediction/runs/159qfjuo?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fWEOSR56xbG9"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "latent_size = 10\n",
        "disc_inp_sz = 224*224\n",
        "img_size = 224\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "width = height = 224\n",
        "# wandb.config = {\n",
        "#   \"learning_rate\": lr,\n",
        "#   \"epochs\": epochs,\n",
        "#   \"batch_size\": batch_size\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "VQqYEWjlxdI8"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "ages = []\n",
        "\n",
        "for image_name in os.listdir('crop_part1')[0:9000]:\n",
        "    part = image_name.split('_')\n",
        "    ages.append(int(part[0]))\n",
        "\n",
        "    image = cv2.imread(f'crop_part1/{image_name}')\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    images.append(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Q0ZzY9UHxept",
        "outputId": "10bbe3cc-53a0-4076-a8fd-ad09b7c710ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-039dff64-f426-4f72-a750-a93229297f5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Images</th>\n",
              "      <th>Ages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[56, 47, 30], [61, 52, 35], [69, 57, 43], [7...</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[109, 70, 65], [110, 71, 66], [113, 75, 72],...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[42, 35, 29], [41, 34, 28], [41, 34, 28], [4...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[134, 104, 54], [126, 96, 46], [116, 86, 34]...</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[198, 198, 198], [195, 195, 195], [191, 191,...</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-039dff64-f426-4f72-a750-a93229297f5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-039dff64-f426-4f72-a750-a93229297f5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-039dff64-f426-4f72-a750-a93229297f5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              Images  Ages\n",
              "0  [[[56, 47, 30], [61, 52, 35], [69, 57, 43], [7...    53\n",
              "1  [[[109, 70, 65], [110, 71, 66], [113, 75, 72],...    10\n",
              "2  [[[42, 35, 29], [41, 34, 28], [41, 34, 28], [4...    29\n",
              "3  [[[134, 104, 54], [126, 96, 46], [116, 86, 34]...    43\n",
              "4  [[[198, 198, 198], [195, 195, 195], [191, 191,...    24"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "images = pd.Series(images, name= 'Images')\n",
        "ages = pd.Series(ages, name= 'Ages')\n",
        "\n",
        "df = pd.concat([images, ages], axis= 1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "ajzyIz7TzvPn",
        "outputId": "5b668ceb-9d8a-48ce-9975-afd09806c182"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(24, 8))\n",
        "plt.hist(df['Ages'], bins= 116)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "7kh60NhSzwyU"
      },
      "outputs": [],
      "source": [
        "under4 = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if df['Ages'].iloc[i] <= 4:\n",
        "        under4.append(df.iloc[i])\n",
        "\n",
        "under4 = pd.DataFrame(under4)\n",
        "under4 = under4.sample(frac= 0.3)\n",
        "\n",
        "up4 = df[df['Ages'] > 4]\n",
        "\n",
        "df = pd.concat([under4, up4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dfDeb_L6zyVT"
      },
      "outputs": [],
      "source": [
        "df = df[df['Ages'] < 90]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "GLFvk0Ipzz3D",
        "outputId": "c6668c18-6cb4-46dd-bd30-21fcd536da4a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(24, 8))\n",
        "plt.hist(df['Ages'], bins= 89)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wSxme9Vz1tj",
        "outputId": "249abb48-6c09-454c-a6a5-857999f82d48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    df['Images'].iloc[i] = cv2.resize(df['Images'].iloc[i], (width, height))\n",
        "\n",
        "    X.append(df['Images'].iloc[i])\n",
        "    Y.append(df['Ages'].iloc[i])\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "A0P2fHSaz4RL"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "jqKbFByTlwgk"
      },
      "outputs": [],
      "source": [
        "# X_train = X_train.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MXpviJ5Hc2Ai"
      },
      "outputs": [],
      "source": [
        "X_train = torch.tensor(X_train)\n",
        "Y_train = torch.tensor(Y_train)\n",
        "X_train = torch.permute(X_train, (0, 3, 2, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HXpu7e97f57Z"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "\n",
        "        # Normalize your data here\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToPILImage(),\n",
        "        torchvision.transforms.Resize((28, 28)),\n",
        "        torchvision.transforms.RandomHorizontalFlip(),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ],
      "metadata": {
        "id": "Z2my2tazRRyo"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MyDataset(X_train, Y_train, transform)\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "5JdSyZV4RW3F"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "3Ys6Qlnjz-yc"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, input_dims, output_dims):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv2d = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, (3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            nn.Conv2d(32, 32, (3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            nn.Conv2d(32, 64, (3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),            \n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(start_dim = 1),\n",
        "            nn.Linear(3136, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, input_t):\n",
        "      x = self.conv2d(input_t)\n",
        "      # print(x.shape)\n",
        "      return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY5XATfw0ATm",
        "outputId": "be955c83-c4c9-4bdf-b347-515d67998a76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (conv2d): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU()\n",
              "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=3136, out_features=256, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
              "    (4): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = MyModel(disc_inp_sz, latent_size).to(device)\n",
        "\n",
        "model = model.to(device)\n",
        "model.train(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "aYb7RowhhO8E"
      },
      "outputs": [],
      "source": [
        " # compile\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_function = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNtXs1aw0EDc",
        "outputId": "a111ab16-b3d8-4145-bfac-3076501aa7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 535.1017456054688\n",
            "Epoch: 2, Loss: 534.508544921875\n",
            "Epoch: 3, Loss: 533.529296875\n",
            "Epoch: 4, Loss: 532.7147827148438\n",
            "Epoch: 5, Loss: 531.9833374023438\n",
            "Epoch: 6, Loss: 531.3654174804688\n",
            "Epoch: 7, Loss: 529.9576416015625\n",
            "Epoch: 8, Loss: 529.8722534179688\n",
            "Epoch: 9, Loss: 528.4984130859375\n",
            "Epoch: 10, Loss: 527.805908203125\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    for images, labels in train_data_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # 1- forwarding\n",
        "        preds = model(images)\n",
        "        # print(labels)\n",
        "        # print(preds)\n",
        "        # 2- backwarding\n",
        "        loss = loss_function(preds, labels.float())\n",
        "        loss.backward()\n",
        "        # 3- Update\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss\n",
        "    \n",
        "    total_loss = train_loss / len(train_data_loader)\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss: {total_loss}\")\n",
        "    wandb.log({'epochs':  epoch,\n",
        "              'loss': total_loss,\n",
        "                              })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "jes77SFI0MUs"
      },
      "outputs": [],
      "source": [
        "# save\n",
        "torch.save(model.state_dict(), \"FaceAgePrediction.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wkEpbDUIeRBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "PyTorch Age Prediction Using Face Image.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOI6CVp5W8byMyZZRjb1SPi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}