{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Persian Mnist Sweep.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTyyEeRWvyZ3FVYSIETqS1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheravi/Deep-Learning/blob/main/PyTorch%20Persian%20Mnist%20TL/Persian_Mnist_Sweep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UDycXg9AInMh"
      },
      "outputs": [],
      "source": [
        "!pip install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDLcb4VJIorz",
        "outputId": "4174a586-03b9-4f1d-f796-1fe2bb8693bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma_heravi\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "msiaBj8PNpI4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }"
      ],
      "metadata": {
        "id": "_5r50kxiIqmK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = {\n",
        "    'name': 'loss',\n",
        "    'goal': 'minimize'   \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric"
      ],
      "metadata": {
        "id": "nweR1Wf3IsEp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_dict = {\n",
        "    'optimizer': {\n",
        "        'values': ['adam', 'sgd']\n",
        "        },\n",
        "    'fc_layer_size': {\n",
        "        'values': [128, 256, 512]\n",
        "        },\n",
        "    'dropout': {\n",
        "          'values': [0.3, 0.4, 0.5]\n",
        "        },\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ],
      "metadata": {
        "id": "ByUi9cJGItTR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_dict.update({\n",
        "    'epochs': {\n",
        "        'value': 1}\n",
        "    })"
      ],
      "metadata": {
        "id": "9tKb-7tGIu25"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "parameters_dict.update({\n",
        "    'learning_rate': {\n",
        "        # a flat distribution between 0 and 0.1\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0,\n",
        "        'max': 0.1\n",
        "      },\n",
        "    'batch_size': {\n",
        "        # integers between 32 and 256\n",
        "        # with evenly-distributed logarithms \n",
        "        'distribution': 'q_log_uniform',\n",
        "        'q': 1,\n",
        "        'min': math.log(32),\n",
        "        'max': math.log(256),\n",
        "      }\n",
        "    })"
      ],
      "metadata": {
        "id": "eXOXMWZwIwtB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWS0_dyEI2J5",
        "outputId": "eab2d388-738a-43d1-cfe1-898e34361b7b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
            " 'parameters': {'batch_size': {'distribution': 'q_log_uniform',\n",
            "                               'max': 5.545177444479562,\n",
            "                               'min': 3.4657359027997265,\n",
            "                               'q': 1},\n",
            "                'dropout': {'values': [0.3, 0.4, 0.5]},\n",
            "                'epochs': {'value': 1},\n",
            "                'fc_layer_size': {'values': [128, 256, 512]},\n",
            "                'learning_rate': {'distribution': 'uniform',\n",
            "                                  'max': 0.1,\n",
            "                                  'min': 0},\n",
            "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-PesianMnist\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb2KWEdFI3hB",
        "outputId": "766d9a83-a941-4528-8e30-65e9f91cb593"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: cj8vwf1f\n",
            "Sweep URL: https://wandb.ai/ma_heravi/pytorch-sweeps-PesianMnist/sweeps/cj8vwf1f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "\n",
        "        loader = build_dataset(config.batch_size)\n",
        "        network = build_network(config.fc_layer_size, config.dropout)\n",
        "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
        "\n",
        "        for epoch in range(1, epochs+1):\n",
        "            total_loss = train_epoch(network, loader, optimizer)\n",
        "            print(f\"Epoch: {epoch+1}, Loss: {total_loss}\")\n",
        "            wandb.log({'epochs':  epoch + 1,\n",
        "              'loss': total_loss,\n",
        "              'acc': total_acc\n",
        "                              })           "
      ],
      "metadata": {
        "id": "q66fm2Y5I5IZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(batch_size):\n",
        "   \n",
        "    transform = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize((28, 28)),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "\n",
        "    dataset = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/MNIST_persian\", transform=transform)\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    return loader\n",
        "\n",
        "\n",
        "def build_network(fc_layer_size, dropout):\n",
        "    network = models.resnet50(pretrained=True)\n",
        "    in_fetures = network.fc.in_features\n",
        "    network.fc = nn.Linear(in_fetures, 1)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # This freezes layers 1-6 in the total 10 layers of Resnet50\n",
        "    ct = 0\n",
        "    for child in network.children():\n",
        "        ct += 1\n",
        "        if ct < 7:\n",
        "            for param in child.parameters():\n",
        "                param.requires_grad = False\n",
        "                \n",
        "    return network.to(device)\n",
        "        \n",
        "\n",
        "def build_optimizer(network, optimizer, learning_rate):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(network.parameters(),\n",
        "                              lr=learning_rate, momentum=0.9)\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(network.parameters(),\n",
        "                               lr=learning_rate)\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "4KBajjH4I6pJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(network, loader, optimizer):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # 1- forwarding\n",
        "        preds = network(images)\n",
        "        # 2- backwarding \n",
        "        loss = loss_function(preds, labels)\n",
        "        loss.backward()\n",
        "        # 3- Update\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss\n",
        "        train_acc += calc_acc(preds, labels)\n",
        "    \n",
        "    total_loss = train_loss / len(loader)\n",
        "    total_acc = train_acc / len(loader)"
      ],
      "metadata": {
        "id": "VHM6AO-9MX7r"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "gyX2aXeEI8-5",
        "outputId": "0dd0e448-b8f9-4efe-c877-0a9f9472b904"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xz1xy36m with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 47\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01755756874335218\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/ma_heravi/pytorch-sweeps-PesianMnist/runs/xz1xy36m\" target=\"_blank\">vivid-sweep-1</a></strong> to <a href=\"https://wandb.ai/ma_heravi/pytorch-sweeps-PesianMnist\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/ma_heravi/pytorch-sweeps-PesianMnist/sweeps/cj8vwf1f\" target=\"_blank\">https://wandb.ai/ma_heravi/pytorch-sweeps-PesianMnist/sweeps/cj8vwf1f</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Processing terminal ouput (stdout)...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"PersianMnistSweepTL.pth\")"
      ],
      "metadata": {
        "id": "BJsj7_u9I-QJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}